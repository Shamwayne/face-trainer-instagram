{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Clustering\n",
    "Face clustering using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "from imutils import paths, build_montages\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] quantifying faces...\n"
     ]
    }
   ],
   "source": [
    "# grab all the image paths of input dataset\n",
    "print(\"[INFO] quantifying faces...\")\n",
    "image_paths = list(paths.list_images(\"./output\"))\n",
    "\n",
    "# creating data store for all our apps\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_method = \"cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing image 1/16\n",
      "./output\\generated-image-1.jpg\n",
      "[INFO] processing image 2/16\n",
      "./output\\generated-image-10.jpg\n",
      "[INFO] processing image 3/16\n",
      "./output\\generated-image-11.jpg\n",
      "[INFO] processing image 4/16\n",
      "./output\\generated-image-12.jpg\n",
      "[INFO] processing image 5/16\n",
      "./output\\generated-image-13.jpg\n",
      "[INFO] processing image 6/16\n",
      "./output\\generated-image-14.jpg\n",
      "[INFO] processing image 7/16\n",
      "./output\\generated-image-15.jpg\n",
      "[INFO] processing image 8/16\n",
      "./output\\generated-image-16.jpg\n",
      "[INFO] processing image 9/16\n",
      "./output\\generated-image-2.jpg\n",
      "[INFO] processing image 10/16\n",
      "./output\\generated-image-3.jpg\n",
      "[INFO] processing image 11/16\n",
      "./output\\generated-image-4.jpg\n",
      "[INFO] processing image 12/16\n",
      "./output\\generated-image-5.jpg\n",
      "[INFO] processing image 13/16\n",
      "./output\\generated-image-6.jpg\n",
      "[INFO] processing image 14/16\n",
      "./output\\generated-image-7.jpg\n",
      "[INFO] processing image 15/16\n",
      "./output\\generated-image-8.jpg\n",
      "[INFO] processing image 16/16\n",
      "./output\\generated-image-9.jpg\n"
     ]
    }
   ],
   "source": [
    "for (i, image_path) in enumerate(image_paths):\n",
    "    # load the input image and convert it from RGB (OpenCV ordering)\n",
    "    # to dlib ordering (RGB)\n",
    "    print(\"[INFO] processing image {}/{}\".format(i + 1, len(image_paths)))\n",
    "    print(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # detect the (x, y) co-ordinates of the bounding boxes\n",
    "    # corresponding to each face in the input image\n",
    "    boxes = face_recognition.face_locations(rgb, model=\"cnn\")\n",
    "    \n",
    "    #compute the facial embedding for the face\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "    d = [{\"imagepath\": image_path, \"loc\": box, \"encoding\": enc}\n",
    "         for (box, enc) in zip(boxes, encodings)]\n",
    "    data.extend(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing encodings...\n"
     ]
    }
   ],
   "source": [
    "# dump the facial encodings data to disk\n",
    "print(\"[INFO] serializing encodings...\")\n",
    "f = open(\"encodings\", \"wb\")\n",
    "f.write(pickle.dumps(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to run the facial clustering algorithm. First thing's first though: we need to reload the face data we stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_jobs = -1 # How many CPUs to run, -1 means use all available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading encodings...\n"
     ]
    }
   ],
   "source": [
    "# load the serialized face encoding + bounding box locations \n",
    "print(\"[INFO] loading encodings...\")\n",
    "data = pickle.loads(open(\"encodings\", \"rb\").read())\n",
    "data = np.array(data)\n",
    "encodings = [d[\"encoding\"] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the DBSCAN (Density-Based Spatial Clustering of Applications with Noise) Algorithm to get all the unique faces. This calculates the Euclidian distance between all the 128 dimension face encodings and groups them into clusters. Not all spaces have the same requirements so tweak the algorithm as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] clustering...\n",
      "[INFO] # unique faces: 1\n"
     ]
    }
   ],
   "source": [
    "# cluster the embeddings\n",
    "print(\"[INFO] clustering...\")\n",
    "cluster = DBSCAN(metric=\"euclidean\", n_jobs=parallel_jobs, min_samples=5)\n",
    "cluster.fit(encodings)\n",
    " \n",
    "# determine the total number of unique faces found in the dataset\n",
    "labelIDs = np.unique(cluster.labels_)\n",
    "numUniqueFaces = len(np.where(labelIDs > -1)[0])\n",
    "print(\"[INFO] # unique faces: {}\".format(numUniqueFaces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] faces for face ID: -1\n"
     ]
    }
   ],
   "source": [
    "# loop over the unique face integers\n",
    "for labelID in labelIDs:\n",
    "    # find all indexes into the `data` array that belong to the\n",
    "    # current label ID, then randomly sample a maximum of 25 indexes\n",
    "    # from the set\n",
    "    print(\"[INFO] faces for face ID: {}\".format(labelID))\n",
    "    idxs = np.where(cluster.labels_ == labelID)[0]\n",
    "    idxs = np.random.choice(idxs, size=min(25, len(idxs)),\n",
    "        replace=False)\n",
    " \n",
    "    # initialize the list of faces to include in the montage\n",
    "    faces = []\n",
    "    \n",
    "    # loop over the sampled indexes\n",
    "    for i in idxs:\n",
    "        # load the input image and extract the face ROI\n",
    "        image = cv2.imread(data[i][\"imagepath\"])\n",
    "        (top, right, bottom, left) = data[i][\"loc\"]\n",
    "        face = image[top:bottom, left:right]\n",
    " \n",
    "        # force resize the face ROI to 96x96 and then add it to the\n",
    "        # faces montage list\n",
    "        face = cv2.resize(face, (96, 96))\n",
    "        faces.append(face)\n",
    "        \n",
    "    montage = build_montages(faces, (96, 96), (5, 5))[0]\n",
    "\n",
    "    # show the output montage\n",
    "    title = \"Face ID #{}\".format(labelID)\n",
    "    title = \"Unknown Faces\" if labelID == -1 else title\n",
    "    cv2.imshow(title, montage)\n",
    "    cv2.waitKey(0)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
